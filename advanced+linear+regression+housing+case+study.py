# -*- coding: utf-8 -*-
"""Advanced+Linear+Regression+Housing+Case+Study.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/kishore-n-george/advanced-linear-regression/blob/main/Advanced%2BLinear%2BRegression%2BHousing%2BCase%2BStudy.ipynb

# Advanced Linear Regression
## Surprise Housing Case Study

#### Problem Statement:

- A US-based housing company named Surprise Housing has decided to enter the Australian market. The company uses data analytics to purchase houses at a price below their actual values and flip them on at a higher price,

- Build a regression model using regularisation in order to predict the actual value of the prospective properties and decide whether to invest in them or not.

## Resusable functions
"""

def calculate_metrics(train,pred):
  """ Calculates important metrics for a given train and predictions"""
  metrics=[]
  r2 = r2_score(train, pred)
  metrics.append(r2)
  print("R2 Score is:", r2)
  rss = np.sum(np.square(train - pred))
  metrics.append(rss)
  print("RSS is ", rss)
  mse = mean_squared_error(train, pred)
  metrics.append(mse)
  print("MSE is: ", mse)
  # Root Mean Squared Error
  rmse = mse**0.5
  metrics.append(rmse)
  print("RMSE is: ", rmse)
  return metrics

def run_cross_validation():
  """ Runs Cross validation for Ridge"""
  params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,
                      2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000]}

  ridge = Ridge()
  # cross validation
  ridgeCV = GridSearchCV(estimator = ridge, 
                          param_grid = params, 
                          scoring= 'neg_mean_absolute_error',  
                          cv = 5, 
                          return_train_score=True,
                          verbose = 1, n_jobs=-1)            
  ridgeCV.fit(X_train, y_train) 

  print(ridgeCV.best_params_)
  return ridgeCV

def do_residual_analysis(y_train, y_train_pred):
  """Does residual analysis and plots residuals"""
  y_res = y_train - y_train_pred
  #y_res
  data = pd.DataFrame({"res":y_res})
  plt.scatter( y_train_pred , data['res'])
  plt.axhline(y=0, color='r', linestyle=':')
  plt.xlabel("Predictions")
  plt.ylabel("Residual")
  plt.show()

# Distribution of errors
  p = sns.distplot(y_res,kde=True)

  p = plt.title('Normality of error terms/residuals')
  plt.xlabel("Residuals")
  plt.show()

def print_metrics(ridge_metrics, lasso_metrics, col1, col2):
  """Print metrics in comparable tabular format"""
  ## Setting float display options
  pd.options.display.float_format = "{:,.2f}".format
  # Creating a table which contain all the metrics
  lr_table = {'Metric': ['R2 Score (Train)','RSS (Train)',
                        'MSE (Train)', 'RMSE (Train)', 'R2 Score (Test)','RSS (Test)',
                        'MSE (Test)', 'RMSE (Test)'],
              col1 : ridge_metrics,
              col2 : lasso_metrics }

  final_metric = pd.DataFrame(lr_table, columns = ['Metric', col1,col2] )
  final_metric.set_index('Metric')
  print(final_metric)

"""# Step 1: Reading and Understanding the Data

Let us first import NumPy and Pandas and read the bike sharing dataset
"""

# Supress Warnings
import warnings
warnings.filterwarnings('ignore')

# importing all the libs here
import numpy as np
import pandas as pd
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
# Importing RFE and LinearRegression
from sklearn.feature_selection import RFE
from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_squared_error, r2_score
# visualisation
import matplotlib.pyplot as plt
import seaborn as sns

"""Loading Data"""

housing = pd.read_csv("train.csv")

# Check the head of the dataset
housing.head()

"""Inspect the various aspects of the dataframe"""

housing.shape
# Inference - 1460 Rows, 81 Columns

housing.info()
# Inference - some columns with null values.
# Data prep needed

"""Check for duplicates"""

# check for duplicate rows based on id
any_duplicates=housing.duplicated(['Id']).any()
print(any_duplicates)
# no duplicate records found

"""Remove Empty columns"""

# remove empty columns
housing = housing.dropna(axis = 1, how = 'all')
housing.info(verbose=True, show_counts=True)

# no columns dropped

"""Drop rows with NA"""

#drop all the rows with only nan values
housing = housing.dropna(axis = 0, how = 'all')
housing.info()
# no of rows remains 1460

"""Drop columns that high percentage of Nan"""

#drop columns that have high percentage of nan
print(housing.shape)
# keep columns where null percentage is less than 60%
housing = housing.loc[:, housing.isnull().mean() < .6]
# four columns with high percentage of nulls dropped
print(housing.shape)

"""Drop rows with high percentage of Nan"""

# drop rows that have high percentage of nan
perc = 60.0 
# calculates minimun number of columns without null value to reach 60%
min_count =  int(((100-perc)/100)*housing.shape[1] + 1)
#atleast 31 columns should be non na
print(min_count)
housing = housing.dropna( axis=0, 
                    thresh=min_count)
housing.shape
# no rows to drop , remains 1460

"""Data Manipulation"""

housing.info()



"""Print all columns with missing values"""

def print_cols_with_missing_values():
  cols_with_missing_values = housing.isnull().sum().sort_values(ascending=False)
  display(pd.DataFrame(cols_with_missing_values[cols_with_missing_values[cols_with_missing_values > 0].index], 
                      columns=["Number of Missing Values"]))
  
print_cols_with_missing_values()

# data cleaning
# check every column which has nulls
# fix nulls
# derive columns from timestamps
# impute data where required

# columns GarageType has nulls -> impute
cat_columns=['FireplaceQu','GarageType','GarageCond','GarageFinish','GarageQual','BsmtFinType1','BsmtFinType2','BsmtExposure','BsmtCond','BsmtQual','MasVnrType']
# FireplaceQU: data description of the variables states that NA represents "no fireplace"
# GarageType: data description of the variables states that NA represents "no garage"
# GarageCond: data description of the variables states that NA represents "no garage"
# GarageFinish: data description of the variables states that NA represents "no garage"
# GarageQual: data description of the variables states that NA represents "no garage"
# BsmtFinType1 : : data description of the variables states that NA represents "no basement"
# BsmtFinType2 : : data description of the variables states that NA represents "no basement"
# BsmtExposure : : data description of the variables states that NA represents "no basement"
# BsmtCond : : data description of the variables states that NA represents "no basement"
# BsmtQual : : data description of the variables states that NA represents "no basement"
# MasVnrType: data description of the variables states that NA represents "no veneer"
for col in cat_columns:
  print(col)
  print('Before Cleaning')
  print(housing[col].isnull().sum())
  print(housing[col].unique())
  housing[col].fillna('None',inplace=True)
  print('After Cleaning')
  print(housing[col].unique())
  print(housing[col].isnull().sum())

# GarageYrBlt -> missing values mean no garage, so impute with 0
# MasVnrArea -> missing values mean no veneer, so impute with 0
num_columns = ['GarageYrBlt','MasVnrArea']
for col in num_columns:
  print(col)
  print('Before Cleaning')
  housing[col].fillna(0,inplace=True)
  print('After Cleaning')
  print(housing[col].isnull().sum())

#Impute electrical
print(housing['Electrical'].unique())
housing['Electrical'].describe()
# SBrkr is most frequently used
# replace one null with SBrkr
housing['Electrical'].fillna('SBrkr',inplace=True)
print(housing['Electrical'].unique())

print_cols_with_missing_values()
# not sure how to impute LotFrontage
print('Before Cleaning')
print(housing['LotFrontage'].unique())
print(housing['LotFrontage'].isnull().sum())
# impute with what? - no clue - read more
# with median for now
housing['LotFrontage'].fillna(housing['LotFrontage'].median(),inplace=True)
print('After Cleaning')
print(housing['LotFrontage'].isnull().sum())

housing.describe()

"""# Step 2: Visualising the Data
Let's now spend some time doing what is arguably the most important step - understanding the data.

If there is some obvious multicollinearity going on, this is the first place to catch it
Here's where you'll also identify if some predictors directly have a strong association with the outcome variable
We'll visualise our data using matplotlib and seaborn.

### Visualize numerical columns
"""

numerical_columns = housing.select_dtypes(include=['number']).columns

for col in numerical_columns:
    plt.figure(figsize=(15,5))
    plt.subplot(1,2,1)
    plt.title(col, fontdict={'fontsize': 18})
    sns.distplot(housing[col])
    plt.subplot(1,2,2)
    sns.boxplot(housing[col])
    plt.show()

"""Most numerical columns have outliers.

### Visualise categorical columns
"""

cat_columns = housing.select_dtypes(include=['object']).columns
for col in cat_columns:
    plt.figure(figsize=(8,5))
    plt.title(col, fontdict={'fontsize': 18})
    sns.barplot(housing[col].value_counts().index, housing[col].value_counts())
    plt.show()

"""Inference - Values of categorical columns are distributed across multiple categories. Cannot remove any columns."""

housing['MSZoning'].unique()

# Build boxplot of all categorical variables (before creating dummies) againt the target variable 'SalePrice' 


def draw_box_plots(columns):
  for col in columns:
      plt.figure(figsize=(25, 10))
      plt.title(col, fontdict={'fontsize': 18})
      sns.boxplot(x = col, y = 'SalePrice', data = housing)
      plt.show()

draw_box_plots(cat_columns)

"""Inference
 - The categorical variables such as SaleCondition,SaleType, GarageQuality, GarageCondition,Electrical,CentralAir heavily influence the sale price. These could be predictors.

Plot Correlation matrix
"""

plt.figure(figsize = (25,20))
sns.heatmap(housing.corr(), annot = True, cmap='RdYlGn')
plt.show()

"""Inference 
- You can see high cor-relation between certain variables.
- SalePrice is most cor-related with OverallQual, YearBuilt, YearRemodAdd, MasVnrArea, TotalBsmtSF, 1stFlrSF,GrLivArea,FullBath,TotRmsAbvGrd, FirePlaces, GarageCars, GarageArea.
- We will use VIF and p-value to select/eliminate certain predictors during model building.

# Step 3: Data preparation and processing.

Outlier Treatment
"""

print(housing.shape)
plt.figure(figsize=[15,15])
plt.xticks(rotation=90)
sns.boxplot(data=housing);

# keeping values which are only greater than quantile(0.01) and less than quantile(0.99).
for col in numerical_columns:
  housing = housing[(housing[col] >= housing[col].quantile(0.01))&(housing[col] <= housing[col].quantile(0.99))]

# check boxplots again to see if outliers are treated
plt.figure(figsize=[15,15])
plt.xticks(rotation=90)
sns.boxplot(data=housing);
print(housing.shape)

# some outliers have been removed. Much lower quantile values reduce the number of rows.

"""Create dummy variables for categorical data

"""

## One hot encoding the categorical columns
print(housing.head(5))
for col in cat_columns:
  # Let's drop the first column from status df using 'drop_first = True'
  encoded = pd.get_dummies(housing[col], drop_first = True, prefix=col)
  # Add the results to the original housing dataframe
  housing = pd.concat([housing, encoded], axis = 1)
  # Drop col as we have created the dummies for it
  housing.drop([col], axis = 1, inplace = True)
print(housing.head(5))

"""#Step 4: Model Building"""

X = housing.drop(["Id", "SalePrice"], axis=1).copy()
X.head()

y = housing["SalePrice"].copy()
y.head()

#train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)
print(X_train.shape)
print(y_train.shape)

"""##Scaling"""

numerical_columns = X_train.select_dtypes(include=['int64', 'float64']).columns

## Create a scaling instance

scaler = StandardScaler()
## Scale the numerical columns 
X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])
X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])

X_train.describe()

"""### MODEL 1 : Ridge Regression"""

## we will run a cross validation on a list of alphas to find the optimum value of alpha
run_cross_validation()

""" Optimum value of alpha is 4.0.
 We will build a Ridge Model using the alpha

"""

alpha = 4
ridge = Ridge(alpha=alpha)
ridge.fit(X_train, y_train)
print(ridge.coef_)

y_train_pred = ridge.predict(X_train)
y_test_pred = ridge.predict(X_test)

train_metrics = calculate_metrics(y_train,y_train_pred)
test_metrics = calculate_metrics(y_test,y_test_pred)

"""High RMSE Value indicates that there might be non-linear relationship between variables. Let us do residual analysis to understand further.

#### Residual Analysis
"""

do_residual_analysis(y_train, y_train_pred)
# inference
# residuals doesnt seem to show a pattern
# residual terms are normally distributed

# plot all the variables vs residuals
for col in numerical_columns:
  plt.scatter( X_train[col] , data['res'])
  plt.axhline(y=0, color='r', linestyle=':')
  plt.xlabel(str(col))
  plt.ylabel("Residual")
  plt.show()

# there is no visible pattern.

"""Let us Analyse the target variable."""

plt.figure(figsize=[10,8])
sns.set_style('darkgrid')
sns.distplot(housing['SalePrice']);
# saleprices are in higher ranges

# let us do a log transformation of saleprice for better model understanding
y_train = np.log(y_train)
y_test = np.log(y_test)

# run cross validation again
ridgeCV = run_cross_validation()

# create new model with new alpha 10
alpha = 10
ridge = Ridge(alpha=alpha)
ridge.fit(X_train, y_train)
print(ridge.coef_)

# predictions again
y_train_pred = ridge.predict(X_train)
y_test_pred = ridge.predict(X_test)

# calculate metrics again
ridge_train_metrics = calculate_metrics(y_train,y_train_pred)
ridge_test_metrics = calculate_metrics(y_test,y_test_pred)

# better scores for both train and test model.

do_residual_analysis(y_train,y_train_pred)

# no visible pattern
# error terms are normally distributed

## Create a dataframe of ridge cross validation results
ridgeCV_results= pd.DataFrame(ridgeCV.cv_results_)
ridgeCV_results

## Plotting R2 score vs alpha values
plt.plot(ridgeCV_results['param_alpha'], ridgeCV_results['mean_train_score'], label='Train')
plt.plot(ridgeCV_results['param_alpha'], ridgeCV_results['mean_test_score'], label='Test')
plt.xlabel('alpha')
plt.ylabel('R2_score')
plt.xscale('log')
plt.legend()
plt.show()
# inference - the best value of alpha is at 10 from the plot.

"""### MODEL2 : Lasso"""

## we will run a cross validation on a list of alphas to find the optimum value of alpha

params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,
                    2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000]}

lasso = Lasso()

# cross validation

lassoCV = GridSearchCV(estimator = lasso, 
                        param_grid = params, 
                        scoring= 'neg_mean_absolute_error',  
                        cv = 5, 
                        return_train_score=True,
                        verbose = 1, n_jobs=-1)            
lassoCV.fit(X_train, y_train)

## View the optimal value of alpha
lassoCV.best_params_

# view the results
lassoCV.cv_results_

# Create a lasso regreesion instance with optimum value alpha=0.001
lasso = Lasso(alpha=0.001)
# Fit the model on training data
lasso.fit(X_train, y_train)

## Make predictions
y_train_pred = lasso.predict(X_train)
y_test_pred = lasso.predict(X_test)

# check metrics for train
print("Training Metrics")
lasso_train_metrics = calculate_metrics(y_train,y_train_pred)
# check metrics for test
print("Testing Metrics")
lasso_test_metrics = calculate_metrics(y_test,y_test_pred)

# the metrics look good for both train and test sets.

do_residual_analysis(y_train,y_train_pred)
# no visible patterns,
# error terms are normally distributed

## Create a dataframe of ridge cross validation results
lassoCV_results= pd.DataFrame(lassoCV.cv_results_)
## Plotting R2 score vs alpha values
plt.plot(lassoCV_results['param_alpha'], lassoCV_results['mean_train_score'], label='Train')
plt.plot(lassoCV_results['param_alpha'], lassoCV_results['mean_test_score'], label='Test')
plt.xlabel('alpha')
plt.ylabel('R2_score')
plt.xscale('log')
plt.legend()
plt.show()

# you can see the best value of alpha is at 0.001

"""### Comparing Ridge and Lasso Models"""

ridge_metrics = ridge_train_metrics + ridge_test_metrics
lasso_metrics = lasso_train_metrics + lasso_test_metrics
print("############### Metrics ##########")
print_metrics(ridge_metrics,lasso_metrics,'Ridge Regression','Lasso Regression')

## Let us check the changes in coefficients after regularization
## First create empty datafame with all the independent variables as indices
coef = pd.DataFrame(index=X.columns)
coef.rows = X.columns
## adding coef to dataframes
coef['Ridge'] = ridge.coef_
coef['Lasso'] = lasso.coef_
print(coef.to_string())
coef.shape

## View the number of features removed by lasso
coef[coef['Lasso']==0].shape

# has removed 175 features out of 232 features

## View the features selected by lasso
coef.loc[coef['Lasso']!=0, 'Lasso']
# 57 features selected by Lasso

"""#### Inference for both Ridge and Lasso"""

## View the top 10 coefficients 
coef['Ridge'].sort_values(ascending=False)[:10]

## View the top 10 coefficients of Lasso in descending order
coef['Lasso'].sort_values(ascending=False)[:10]

"""Inference:
- Neighborhood_Crawfor: if Crawford is a nearby location, then the price of house will increase by 0.08 times
- YearBuilt : Depending upon the value of year built the sale price will increase from 0.06 to 0.07 times
- GrLivArea - an increase of 1 square foot of house area above ground, the price will increase by 0.06 to 0.10 times
- Condition1_Norm - proximity to normal conditions will increase sale price by 0.05 to 0.06 times

# Code for subjective questions

## Question 1
"""

# Question 1
# doubling value of alpha in ridge 10 -> 100

# create new model with new alpha 100
alpha = 100
ridge2 = Ridge(alpha=alpha)
ridge2.fit(X_train, y_train)
print(ridge2.coef_)

# predictions again
y_train_pred = ridge2.predict(X_train)
y_test_pred = ridge2.predict(X_test)

# calculate metrics again
new_ridge_train_metrics = calculate_metrics(y_train,y_train_pred)
new_ridge_test_metrics = calculate_metrics(y_test,y_test_pred)

new_ridge_metrics = new_ridge_train_metrics + new_ridge_test_metrics

print_metrics(ridge_metrics,new_ridge_metrics, 'Ridge - Original', 'Ridge - Doubled')
# Train R2 score has dropped for the new model
# Train RMSE has increased
# Test R2 score has dropped for the new model
# Test RMSE remains same

# Create a lasso regreesion instance with optimum value alpha=0.000001
alpha = 0.001 * 0.001
lasso2 = Lasso(alpha=alpha)
# Fit the model on training data
lasso2.fit(X_train, y_train)

## Make predictions
y_train_pred = lasso2.predict(X_train)
y_test_pred = lasso2.predict(X_test)

# check metrics for train
print("Training Metrics")
new_lasso_train_metrics = calculate_metrics(y_train,y_train_pred)
# check metrics for test
print("Testing Metrics")
new_lasso_test_metrics = calculate_metrics(y_test,y_test_pred)

new_lasso_metrics = new_lasso_train_metrics + new_lasso_test_metrics

print_metrics(lasso_metrics,new_lasso_metrics, 'Lasso - Original', 'Lasso - Doubled')
# R2 score for training has improved 
# RMSE for training has decrease
# the test R2 score has improved
# RMSE for testing remains same

coef2 = pd.DataFrame(index=X.columns)
coef2.rows = X.columns
## adding coef to dataframes
coef2['Ridge'] = ridge2.coef_
coef2['Lasso'] = lasso2.coef_

# printing new variables for Ridge
coef2['Ridge'].sort_values(ascending=False)[:10]

# printing new variables for Lasso
coef2['Lasso'].sort_values(ascending=False)[:10]

"""## Question 3"""

# drop the five important Lasso predictors.
# GrLivArea              0.10
# Neighborhood_Crawfor   0.08
# YearBuilt              0.07
# OverallQual            0.06
# Neighborhood_Somerst   0.06

cols_to_drop=['GrLivArea','Neighborhood_Crawfor','YearBuilt','OverallQual','Neighborhood_Somerst']

# drop them from train and test data

## drop them from train and test data
X_train_dropped = X_train.drop(cols_to_drop, axis=1)
X_test_dropped = X_test.drop(cols_to_drop, axis=1)

# build lasso model again
params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,
                    2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000]}

lasso2 = Lasso()

# cross validation

lassoCV2 = GridSearchCV(estimator = lasso2, 
                        param_grid = params, 
                        scoring= 'neg_mean_absolute_error',  
                        cv = 5, 
                        return_train_score=True,
                        verbose = 1, n_jobs=-1)            
lassoCV2.fit(X_train_dropped, y_train) 

## View the optimal value of alpha
print(lassoCV.best_params_)

# Create a lasso instance with optimum value alpha=0.001
lasso3 = Lasso(alpha=0.001)
# Fit the model on training data
lasso3.fit(X_train_dropped, y_train)

## Make predictions
y_train_pred = lasso3.predict(X_train_dropped)
y_test_pred = lasso3.predict(X_test_dropped)

# check metrics for train
print("Training Metrics")
lasso3_train_metrics = calculate_metrics(y_train,y_train_pred)
# check metrics for test
print("Testing Metrics")
lasso3_test_metrics = calculate_metrics(y_test,y_test_pred)

lasso3_metrics = lasso3_train_metrics + lasso3_test_metrics

print_metrics(lasso_metrics,lasso3_metrics, 'Lasso - Original', 'Lasso - Dropped')

## First create empty datafame with all the independent variables as indices
dropped_betas = pd.DataFrame(index=X_train_dropped.columns)
dropped_betas.rows = X_train_dropped.columns
dropped_betas['Lasso'] = lasso3.coef_
dropped_betas['Lasso'].sort_values(ascending=False)[:5]